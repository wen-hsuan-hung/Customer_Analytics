{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93f0131",
   "metadata": {},
   "source": [
    "## S-Mobile: Predicting Customer Churn\n",
    "* Team-lead GitLab id: 243\n",
    "* Group name: Korinna\n",
    "* Team member names: Siqi Chen, Wen-Hsuan Hung, Xinyu Lou, Yuefeng Mao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c94118",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Please complete this Jupyter notebook by answering the questions in `s-mobile.pdf` on Canvas (week9/). Create a Notebook and HTML file with all your results and comments and push both the Notebook and HTML file to GitLab when your team is done. All results MUST be reproducible (i.e., the TA and I must be able to recreate the HTML from the Jupyter Notebook file without changes or errors). This means that you should NOT use any python-packages that are not part of the rsm-msba-spark docker container.\n",
    "\n",
    "This is the fourth group assignment for MGTA 455 and you will be using git and GitLab. If two people edit the same file at the same time you could get what is called a \"merge conflict\". git will not decide for you who's change to accept so the team-lead will have to determine which edits to use. To avoid merge conflicts, **always** \"pull\" changes to the repo before you start working on any files. Then, when you are done, save and commit your changes, and then push them to GitLab. Make \"pull first\" a habit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c7f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from tempfile import NamedTemporaryFile as tmpfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyrsm as rsm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.genmod.families import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.genmod.families import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report, roc_curve, auc, make_scorer,mean_squared_error,r2_score\n",
    "from sklearn.inspection import plot_partial_dependence \n",
    "\n",
    "import statsmodels.formula.api as smf \n",
    "from statsmodels.genmod.families import Binomial \n",
    "from statsmodels.genmod.families.links import logit \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# increase plot resolution\n",
    "mpl.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a814641",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data - this dataset must NOT be changed\n",
    "s_mobile = pd.read_pickle(\"data/s_mobile.pkl\")\n",
    "s_mobile[\"churn_yes\"] = rsm.ifelse(s_mobile[\"churn\"] == \"yes\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df951b73",
   "metadata": {},
   "source": [
    "If you want access to the full 1M row dataset, use the code below to download and use the data. Please do **not** include the 1M row dataset in your repo!\n",
    "\n",
    "The downside to using the dataset with 1M rows is, of course, that estimation time will increase substantially. I do NOT recommend you use this dataset to select your final model or for tuning hyper parameters. You can, however, use this larger dataset to re-estimate your chosen model and generate profit estimates for the representative sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101250f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment to run\n",
    "# url = \"https://www.dropbox.com/s/xhiexneeok9gyhs/s_mobile_1M.pkl.zip?dl=1\"\n",
    "# file_path, _ = urllib.request.urlretrieve(url)\n",
    "# zip_file = zipfile.ZipFile(file_path, \"r\")\n",
    "# s_mobile_tmp = zip_file.open(zip_file.namelist()[0])\n",
    "# os.remove(file_path)\n",
    "# s_mobile = pd.read_pickle(s_mobile_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88b6d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## S-mobile\n",
       "\n",
       "Dataset used to investigate opportunities to decrease customer churn at S-mobile. The sample consists of three parts:\n",
       "\n",
       "1. A training sample with 27,300 observations and a 50% churn rate (\"training == 1\")\n",
       "2. A test sample with 11,700 observations and a 50% churn rate (\"training == 0\")\n",
       "3. A representative sample with 30,000 observations and a churn rate of 2%, i.e., the actual monthly churn rate for S-mobile (\"is.na(training)\" or \"representative == 1\")\n",
       "\n",
       "## Variables\n",
       "\n",
       "* customer: Customer ID\n",
       "* churn: Did consumer churn in the last 30 days? (yes or no)\n",
       "* changer: % change in revenue over the most recent 4 month period\n",
       "* changem: % change in minutes of use over the most recent 4 month period\n",
       "* revenue: Mean monthly revenue in SGD\n",
       "* mou: Mean monthly minutes of use\n",
       "* overage: Mean monthly overage minutes\n",
       "* roam: Mean number of roaming calls\n",
       "* conference: Mean number of conference calls\n",
       "* months: # of months the customer has had service with S-Mobile\n",
       "* uniqsubs: Number of individuals listed on the customer account\n",
       "* custcare: Mean number of calls to customer care \n",
       "* retcalls: Number of calls by the customer to the retention team\n",
       "* dropvce: Mean number of dropped voice calls \n",
       "* eqpdays: Number of days customer has owned current handset\n",
       "* refurb: Handset is refurbished (no or yes)\n",
       "* smartphone: Handset is a smartphone (no or yes)\n",
       "* creditr: High credit rating as opposed to medium or low (no or yes)\n",
       "* mcycle: Subscriber owns a motorcycle (no or yes)\n",
       "* car: Subscriber owns a car (no or yes)\n",
       "* travel: Subscriber has traveled internationally (no or yes)\n",
       "* region: Regions delineated by the 5 Community Development Council Districts (e.g., CS is Central Singapore)\n",
       "* occupation: Categorical variable with 4 occupation levels (professional, student, retired, or other)\n",
       "* training: 1 for training sample, 0 for test sample, NA for representative sample\n",
       "* representative: 1 for representative sample, 0 for training and test sample\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show dataset description\n",
    "rsm.describe(s_mobile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc9e2c9",
   "metadata": {},
   "source": [
    "Use `smf.glm` with `freq_weights` and `cov_type` like in the below example\n",
    "    \n",
    "```python\n",
    "lr = smf.glm(\n",
    "    formula=\"churn_yes ~ changer + changem + ...\",\n",
    "    family=Binomial(link=logit()),\n",
    "    data=pentathlon_nptb.query(\"training == 1\"),\n",
    "    freq_weights=s_mobile.loc[mobile.training == 1, \"cweight\"],\n",
    ").fit(cov_type=\"HC1\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ac99f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index     OR   OR%  2.5%  97.5% p.values    \n",
      "1  changer  1.001  0.1%   1.0  1.002    0.006  **\n"
     ]
    }
   ],
   "source": [
    "# run python code from another notebook\n",
    "%run ./sub-notebooks/model1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28594373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You just accessed a function from your first python packages!\n",
      "Change the code in utils/function.py to whatever you need for this assignment\n",
      "Use 'from utils import functions' to get access to your code\n",
      "You can add modules to import from by adding additional .py files to the 'utils' directory\n",
      "Note: If you make changes to the content of this file you will have to restart the notebook kernel to get the updates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing functions from a module/package\n",
    "from utils import functions\n",
    "\n",
    "functions.example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69730a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057b60e",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05229182",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mobile[\"cweight\"] = rsm.ifelse(s_mobile.churn == \"yes\", 2, 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc57b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_std = s_mobile.loc[:, \"changer\":\"eqpdays\"].columns\n",
    "\n",
    "# scale numeric variables by (x - mean(x)) / sd(x)\n",
    "s_mobile_std = s_mobile.copy()\n",
    "s_mobile_std[to_std] = rsm.scale_df(\n",
    "   s_mobile[to_std], sf=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1558442",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mobile_train = s_mobile[s_mobile['training'] == 1]\n",
    "s_mobile_test = s_mobile[s_mobile['training'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682271c",
   "metadata": {},
   "source": [
    "## Model comparison: Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6db070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['refurb' , 'smartphone' , 'highcreditr' , 'mcycle' , 'car' ,'travel' , 'region' , 'occupation']\n",
    "\n",
    "X_train_catagroy= pd.get_dummies(s_mobile_std[columns])\n",
    "X_num = s_mobile_std.loc[:,\"changer\":\"eqpdays\"]\n",
    "X_index = s_mobile_std.loc[:,\"training\":\"representative\"]\n",
    "\n",
    "X = pd.concat([X_train_catagroy,X_num,X_index],axis=1)\n",
    "\n",
    "X_train = X[X['training']==1]\n",
    "X_test = X[X['training']==0]\n",
    "X_repre = X[X['representative']==1]\n",
    "\n",
    "X_train = X_train.drop(['training','representative'],axis=1)\n",
    "X_test =  X_test.drop(['training','representative'],axis=1)\n",
    "X_repre = X_repre.drop(['training','representative'],axis=1)\n",
    "\n",
    "Y_train = s_mobile_std[s_mobile_std['training']==1][\"churn_yes\"]\n",
    "Y_test = s_mobile_std[s_mobile_std['training']==0][\"churn_yes\"]\n",
    "Y_repre = s_mobile_std[s_mobile_std['representative']==1][\"churn_yes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ed31b",
   "metadata": {},
   "source": [
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ee758e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators= 50 max_depth= 1 learning_rate= 0.4  AUROC on testing set= 0.7238125210022646\n",
      "n_estimators= 50 max_depth= 1 learning_rate= 0.45  AUROC on testing set= 0.727327430783841\n",
      "n_estimators= 50 max_depth= 1 learning_rate= 0.5  AUROC on testing set= 0.728751654613193\n",
      "n_estimators= 50 max_depth= 1 learning_rate= 0.55  AUROC on testing set= 0.7299038351961429\n",
      "n_estimators= 50 max_depth= 2 learning_rate= 0.4  AUROC on testing set= 0.7486488567462927\n",
      "n_estimators= 50 max_depth= 2 learning_rate= 0.45  AUROC on testing set= 0.7461704288114546\n",
      "n_estimators= 50 max_depth= 2 learning_rate= 0.5  AUROC on testing set= 0.7519846007743444\n",
      "n_estimators= 50 max_depth= 2 learning_rate= 0.55  AUROC on testing set= 0.7522140550807218\n",
      "n_estimators= 50 max_depth= 3 learning_rate= 0.4  AUROC on testing set= 0.7570113521805829\n",
      "n_estimators= 50 max_depth= 3 learning_rate= 0.45  AUROC on testing set= 0.7556136021623201\n",
      "n_estimators= 50 max_depth= 3 learning_rate= 0.5  AUROC on testing set= 0.7553255168383374\n",
      "n_estimators= 50 max_depth= 3 learning_rate= 0.55  AUROC on testing set= 0.7537627876397106\n",
      "n_estimators= 50 max_depth= 4 learning_rate= 0.4  AUROC on testing set= 0.7572388487106436\n",
      "n_estimators= 50 max_depth= 4 learning_rate= 0.45  AUROC on testing set= 0.753962992183505\n",
      "n_estimators= 50 max_depth= 4 learning_rate= 0.5  AUROC on testing set= 0.7533647892468405\n",
      "n_estimators= 50 max_depth= 4 learning_rate= 0.55  AUROC on testing set= 0.749404996712689\n",
      "n_estimators= 60 max_depth= 1 learning_rate= 0.4  AUROC on testing set= 0.726139513477975\n",
      "n_estimators= 60 max_depth= 1 learning_rate= 0.45  AUROC on testing set= 0.730029147490686\n",
      "n_estimators= 60 max_depth= 1 learning_rate= 0.5  AUROC on testing set= 0.7293527065527066\n",
      "n_estimators= 60 max_depth= 1 learning_rate= 0.55  AUROC on testing set= 0.7315704142011834\n",
      "n_estimators= 60 max_depth= 2 learning_rate= 0.4  AUROC on testing set= 0.7516839067864708\n",
      "n_estimators= 60 max_depth= 2 learning_rate= 0.45  AUROC on testing set= 0.7483252100226461\n",
      "n_estimators= 60 max_depth= 2 learning_rate= 0.5  AUROC on testing set= 0.7524820658923224\n",
      "n_estimators= 60 max_depth= 2 learning_rate= 0.55  AUROC on testing set= 0.7544002922054205\n",
      "n_estimators= 60 max_depth= 3 learning_rate= 0.4  AUROC on testing set= 0.7577201110380597\n",
      "n_estimators= 60 max_depth= 3 learning_rate= 0.45  AUROC on testing set= 0.757465439403901\n",
      "n_estimators= 60 max_depth= 3 learning_rate= 0.5  AUROC on testing set= 0.7560249689531741\n",
      "n_estimators= 60 max_depth= 3 learning_rate= 0.55  AUROC on testing set= 0.7531103952078311\n",
      "n_estimators= 60 max_depth= 4 learning_rate= 0.4  AUROC on testing set= 0.7570103586821536\n",
      "n_estimators= 60 max_depth= 4 learning_rate= 0.45  AUROC on testing set= 0.7529321499013807\n",
      "n_estimators= 60 max_depth= 4 learning_rate= 0.5  AUROC on testing set= 0.7526377821608591\n",
      "n_estimators= 60 max_depth= 4 learning_rate= 0.55  AUROC on testing set= 0.74927974285923\n",
      "n_estimators= 70 max_depth= 1 learning_rate= 0.4  AUROC on testing set= 0.7293112572138213\n",
      "n_estimators= 70 max_depth= 1 learning_rate= 0.45  AUROC on testing set= 0.7315795456205713\n",
      "n_estimators= 70 max_depth= 1 learning_rate= 0.5  AUROC on testing set= 0.7327511870845204\n",
      "n_estimators= 70 max_depth= 1 learning_rate= 0.55  AUROC on testing set= 0.7348404266199138\n",
      "n_estimators= 70 max_depth= 2 learning_rate= 0.4  AUROC on testing set= 0.7541653298268682\n",
      "n_estimators= 70 max_depth= 2 learning_rate= 0.45  AUROC on testing set= 0.7497592519541236\n",
      "n_estimators= 70 max_depth= 2 learning_rate= 0.5  AUROC on testing set= 0.7549668346847834\n",
      "n_estimators= 70 max_depth= 2 learning_rate= 0.55  AUROC on testing set= 0.7567004748338082\n",
      "n_estimators= 70 max_depth= 3 learning_rate= 0.4  AUROC on testing set= 0.7581906202060048\n",
      "n_estimators= 70 max_depth= 3 learning_rate= 0.45  AUROC on testing set= 0.7594423405654176\n",
      "n_estimators= 70 max_depth= 3 learning_rate= 0.5  AUROC on testing set= 0.7581804076265615\n",
      "n_estimators= 70 max_depth= 3 learning_rate= 0.55  AUROC on testing set= 0.753026386149463\n",
      "n_estimators= 70 max_depth= 4 learning_rate= 0.4  AUROC on testing set= 0.7586335744028052\n",
      "n_estimators= 70 max_depth= 4 learning_rate= 0.45  AUROC on testing set= 0.7545990649426546\n",
      "n_estimators= 70 max_depth= 4 learning_rate= 0.5  AUROC on testing set= 0.7521875666593616\n",
      "n_estimators= 70 max_depth= 4 learning_rate= 0.55  AUROC on testing set= 0.7477153773102492\n",
      "n_estimators= 80 max_depth= 1 learning_rate= 0.4  AUROC on testing set= 0.7310072613046972\n",
      "n_estimators= 80 max_depth= 1 learning_rate= 0.45  AUROC on testing set= 0.7338235663671562\n",
      "n_estimators= 80 max_depth= 1 learning_rate= 0.5  AUROC on testing set= 0.7348592300387172\n",
      "n_estimators= 80 max_depth= 1 learning_rate= 0.55  AUROC on testing set= 0.7367613120023376\n",
      "n_estimators= 80 max_depth= 2 learning_rate= 0.4  AUROC on testing set= 0.7554109138724523\n",
      "n_estimators= 80 max_depth= 2 learning_rate= 0.45  AUROC on testing set= 0.7509756885090219\n",
      "n_estimators= 80 max_depth= 2 learning_rate= 0.5  AUROC on testing set= 0.7549542990722478\n",
      "n_estimators= 80 max_depth= 2 learning_rate= 0.55  AUROC on testing set= 0.7573723865877711\n",
      "n_estimators= 80 max_depth= 3 learning_rate= 0.4  AUROC on testing set= 0.7596470450726862\n",
      "n_estimators= 80 max_depth= 3 learning_rate= 0.45  AUROC on testing set= 0.7579441303236174\n",
      "n_estimators= 80 max_depth= 3 learning_rate= 0.5  AUROC on testing set= 0.7573873913361092\n",
      "n_estimators= 80 max_depth= 3 learning_rate= 0.55  AUROC on testing set= 0.7524177514792898\n",
      "n_estimators= 80 max_depth= 4 learning_rate= 0.4  AUROC on testing set= 0.757437051647308\n",
      "n_estimators= 80 max_depth= 4 learning_rate= 0.45  AUROC on testing set= 0.7526539411206079\n",
      "n_estimators= 80 max_depth= 4 learning_rate= 0.5  AUROC on testing set= 0.7543007524289576\n",
      "n_estimators= 80 max_depth= 4 learning_rate= 0.55  AUROC on testing set= 0.7456429541968004\n",
      "n_estimators= 90 max_depth= 1 learning_rate= 0.4  AUROC on testing set= 0.7323452699247571\n",
      "n_estimators= 90 max_depth= 1 learning_rate= 0.45  AUROC on testing set= 0.7355896559281174\n",
      "n_estimators= 90 max_depth= 1 learning_rate= 0.5  AUROC on testing set= 0.7359949010154139\n",
      "n_estimators= 90 max_depth= 1 learning_rate= 0.55  AUROC on testing set= 0.7373551172474249\n",
      "n_estimators= 90 max_depth= 2 learning_rate= 0.4  AUROC on testing set= 0.756027759514939\n",
      "n_estimators= 90 max_depth= 2 learning_rate= 0.45  AUROC on testing set= 0.7528254218715758\n",
      "n_estimators= 90 max_depth= 2 learning_rate= 0.5  AUROC on testing set= 0.7551434144203374\n",
      "n_estimators= 90 max_depth= 2 learning_rate= 0.55  AUROC on testing set= 0.7584466944261816\n",
      "n_estimators= 90 max_depth= 3 learning_rate= 0.4  AUROC on testing set= 0.7597722112645189\n",
      "n_estimators= 90 max_depth= 3 learning_rate= 0.45  AUROC on testing set= 0.7579935568704799\n",
      "n_estimators= 90 max_depth= 3 learning_rate= 0.5  AUROC on testing set= 0.7556018408941486\n",
      "n_estimators= 90 max_depth= 3 learning_rate= 0.55  AUROC on testing set= 0.7521275914968223\n",
      "n_estimators= 90 max_depth= 4 learning_rate= 0.4  AUROC on testing set= 0.7569940974505076\n",
      "n_estimators= 90 max_depth= 4 learning_rate= 0.45  AUROC on testing set= 0.7518027175104097\n",
      "n_estimators= 90 max_depth= 4 learning_rate= 0.5  AUROC on testing set= 0.7552082255825847\n",
      "n_estimators= 90 max_depth= 4 learning_rate= 0.55  AUROC on testing set= 0.7458279494484623\n",
      "n_estimators= 100 max_depth= 1 learning_rate= 0.4  AUROC on testing set= 0.7336840967199942\n",
      "n_estimators= 100 max_depth= 1 learning_rate= 0.45  AUROC on testing set= 0.7361606837606838\n",
      "n_estimators= 100 max_depth= 1 learning_rate= 0.5  AUROC on testing set= 0.7378670611439844\n",
      "n_estimators= 100 max_depth= 1 learning_rate= 0.55  AUROC on testing set= 0.7383794287384031\n",
      "n_estimators= 100 max_depth= 2 learning_rate= 0.4  AUROC on testing set= 0.7575072101687486\n",
      "n_estimators= 100 max_depth= 2 learning_rate= 0.45  AUROC on testing set= 0.7551200964277888\n",
      "n_estimators= 100 max_depth= 2 learning_rate= 0.5  AUROC on testing set= 0.7566886112937395\n",
      "n_estimators= 100 max_depth= 2 learning_rate= 0.55  AUROC on testing set= 0.7588372561911023\n",
      "n_estimators= 100 max_depth= 3 learning_rate= 0.4  AUROC on testing set= 0.7598828986777706\n",
      "n_estimators= 100 max_depth= 3 learning_rate= 0.45  AUROC on testing set= 0.7570904375776171\n",
      "n_estimators= 100 max_depth= 3 learning_rate= 0.5  AUROC on testing set= 0.7562698370954781\n",
      "n_estimators= 100 max_depth= 3 learning_rate= 0.55  AUROC on testing set= 0.7516544378698224\n",
      "n_estimators= 100 max_depth= 4 learning_rate= 0.4  AUROC on testing set= 0.7571211045364892\n",
      "n_estimators= 100 max_depth= 4 learning_rate= 0.45  AUROC on testing set= 0.74995519029878\n",
      "n_estimators= 100 max_depth= 4 learning_rate= 0.5  AUROC on testing set= 0.74903908247498\n",
      "n_estimators= 100 max_depth= 4 learning_rate= 0.55  AUROC on testing set= 0.7454493973263204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 3, 0.4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search\n",
    "learning_rate = list(np.arange(0.4,0.6,0.05))\n",
    "n_estimators = range(50,110,10)\n",
    "max_depth = range(1,5)\n",
    "\n",
    "def gridsearch_gb(learning_rate,n_estimators,max_depth):\n",
    "    params_scores = {}\n",
    "    for j in n_estimators:\n",
    "        for k in max_depth:\n",
    "            for g in learning_rate:\n",
    "                model = GradientBoostingClassifier(n_estimators=j,max_depth=k,learning_rate=g).fit(X_train,Y_train)\n",
    "                y_pred = model.predict_proba(X_test)[:,1]\n",
    "                score = roc_auc_score(Y_test, y_pred)\n",
    "                params_scores[(j,k,g)] = score\n",
    "                print(\"n_estimators=\",j,\"max_depth=\",k,\"learning_rate=\",g,\" AUROC on testing set=\",score)\n",
    "    return max(params_scores, key=params_scores.get)\n",
    "\n",
    "gridsearch_gb(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a04c16",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ce02fb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators= 10 max_depth= 2  AUROC on testing set= 0.6818138943677405\n",
      "n_estimators= 10 max_depth= 4  AUROC on testing set= 0.6953303820585872\n",
      "n_estimators= 10 max_depth= 6  AUROC on testing set= 0.7133400394477317\n",
      "n_estimators= 10 max_depth= 8  AUROC on testing set= 0.7175716414639493\n",
      "n_estimators= 10 max_depth= 10  AUROC on testing set= 0.7174326247351888\n",
      "n_estimators= 10 max_depth= 12  AUROC on testing set= 0.7193188983855651\n",
      "n_estimators= 10 max_depth= 14  AUROC on testing set= 0.7140423990065016\n",
      "n_estimators= 10 max_depth= 16  AUROC on testing set= 0.7080802688289868\n",
      "n_estimators= 10 max_depth= 18  AUROC on testing set= 0.7071766820074512\n",
      "n_estimators= 10 max_depth= 20  AUROC on testing set= 0.692428563079845\n",
      "n_estimators= 10 max_depth= 22  AUROC on testing set= 0.6983472569216158\n",
      "n_estimators= 10 max_depth= 24  AUROC on testing set= 0.6950752428957558\n",
      "n_estimators= 10 max_depth= 26  AUROC on testing set= 0.6900980056980056\n",
      "n_estimators= 10 max_depth= 28  AUROC on testing set= 0.690027744904668\n",
      "n_estimators= 20 max_depth= 2  AUROC on testing set= 0.6973652421652421\n",
      "n_estimators= 20 max_depth= 4  AUROC on testing set= 0.7054978157644824\n",
      "n_estimators= 20 max_depth= 6  AUROC on testing set= 0.7132748484184381\n",
      "n_estimators= 20 max_depth= 8  AUROC on testing set= 0.7212300094966761\n",
      "n_estimators= 20 max_depth= 10  AUROC on testing set= 0.7264419168675579\n",
      "n_estimators= 20 max_depth= 12  AUROC on testing set= 0.7263388706260501\n",
      "n_estimators= 20 max_depth= 14  AUROC on testing set= 0.7292142888450581\n",
      "n_estimators= 20 max_depth= 16  AUROC on testing set= 0.726799342537804\n",
      "n_estimators= 20 max_depth= 18  AUROC on testing set= 0.721031265979984\n",
      "n_estimators= 20 max_depth= 20  AUROC on testing set= 0.719373745342976\n",
      "n_estimators= 20 max_depth= 22  AUROC on testing set= 0.7107947549127036\n",
      "n_estimators= 20 max_depth= 24  AUROC on testing set= 0.713854218715757\n",
      "n_estimators= 20 max_depth= 26  AUROC on testing set= 0.7111297392066622\n",
      "n_estimators= 20 max_depth= 28  AUROC on testing set= 0.7133066403681788\n",
      "n_estimators= 30 max_depth= 2  AUROC on testing set= 0.6978079918182483\n",
      "n_estimators= 30 max_depth= 4  AUROC on testing set= 0.7070188618598875\n",
      "n_estimators= 30 max_depth= 6  AUROC on testing set= 0.7138474833808167\n",
      "n_estimators= 30 max_depth= 8  AUROC on testing set= 0.724554401344145\n",
      "n_estimators= 30 max_depth= 10  AUROC on testing set= 0.7274694864489736\n",
      "n_estimators= 30 max_depth= 12  AUROC on testing set= 0.7307984659215427\n",
      "n_estimators= 30 max_depth= 14  AUROC on testing set= 0.7283367813572942\n",
      "n_estimators= 30 max_depth= 16  AUROC on testing set= 0.7292089853166777\n",
      "n_estimators= 30 max_depth= 18  AUROC on testing set= 0.7262630287091825\n",
      "n_estimators= 30 max_depth= 20  AUROC on testing set= 0.7256849879465264\n",
      "n_estimators= 30 max_depth= 22  AUROC on testing set= 0.7191505150120534\n",
      "n_estimators= 30 max_depth= 24  AUROC on testing set= 0.7177148367302214\n",
      "n_estimators= 30 max_depth= 26  AUROC on testing set= 0.7154147563737306\n",
      "n_estimators= 30 max_depth= 28  AUROC on testing set= 0.7162194608809993\n",
      "n_estimators= 40 max_depth= 2  AUROC on testing set= 0.6884119365914237\n",
      "n_estimators= 40 max_depth= 4  AUROC on testing set= 0.7088727007085982\n",
      "n_estimators= 40 max_depth= 6  AUROC on testing set= 0.717533727810651\n",
      "n_estimators= 40 max_depth= 8  AUROC on testing set= 0.723269705603039\n",
      "n_estimators= 40 max_depth= 10  AUROC on testing set= 0.7305775732339834\n",
      "n_estimators= 40 max_depth= 12  AUROC on testing set= 0.7337181532617431\n",
      "n_estimators= 40 max_depth= 14  AUROC on testing set= 0.7319476660092045\n",
      "n_estimators= 40 max_depth= 16  AUROC on testing set= 0.7320707137117394\n",
      "n_estimators= 40 max_depth= 18  AUROC on testing set= 0.7310673825699465\n",
      "n_estimators= 40 max_depth= 20  AUROC on testing set= 0.7280506684198992\n",
      "n_estimators= 40 max_depth= 22  AUROC on testing set= 0.724971524581781\n",
      "n_estimators= 40 max_depth= 24  AUROC on testing set= 0.7267592519541237\n",
      "n_estimators= 40 max_depth= 26  AUROC on testing set= 0.7237735846299949\n",
      "n_estimators= 40 max_depth= 28  AUROC on testing set= 0.7222501278398714\n",
      "n_estimators= 50 max_depth= 2  AUROC on testing set= 0.7012907443933085\n",
      "n_estimators= 50 max_depth= 4  AUROC on testing set= 0.7064539265103368\n",
      "n_estimators= 50 max_depth= 6  AUROC on testing set= 0.7168919862663452\n",
      "n_estimators= 50 max_depth= 8  AUROC on testing set= 0.7258617283950617\n",
      "n_estimators= 50 max_depth= 10  AUROC on testing set= 0.7308815107020236\n",
      "n_estimators= 50 max_depth= 12  AUROC on testing set= 0.7328410548615678\n",
      "n_estimators= 50 max_depth= 14  AUROC on testing set= 0.7354485791511433\n",
      "n_estimators= 50 max_depth= 16  AUROC on testing set= 0.7330993352326686\n",
      "n_estimators= 50 max_depth= 18  AUROC on testing set= 0.7339667178026154\n",
      "n_estimators= 50 max_depth= 20  AUROC on testing set= 0.7304877638980204\n",
      "n_estimators= 50 max_depth= 22  AUROC on testing set= 0.7292591277668201\n",
      "n_estimators= 50 max_depth= 24  AUROC on testing set= 0.7267642778873549\n",
      "n_estimators= 50 max_depth= 26  AUROC on testing set= 0.7266859814449558\n",
      "n_estimators= 50 max_depth= 28  AUROC on testing set= 0.7188692234640952\n",
      "n_estimators= 60 max_depth= 2  AUROC on testing set= 0.6920188180290745\n",
      "n_estimators= 60 max_depth= 4  AUROC on testing set= 0.7091561107458544\n",
      "n_estimators= 60 max_depth= 6  AUROC on testing set= 0.7173911315654905\n",
      "n_estimators= 60 max_depth= 8  AUROC on testing set= 0.7253760975966105\n",
      "n_estimators= 60 max_depth= 10  AUROC on testing set= 0.7311428300094966\n",
      "n_estimators= 60 max_depth= 12  AUROC on testing set= 0.7346631894221637\n",
      "n_estimators= 60 max_depth= 14  AUROC on testing set= 0.7357163708086785\n",
      "n_estimators= 60 max_depth= 16  AUROC on testing set= 0.7339140916063992\n",
      "n_estimators= 60 max_depth= 18  AUROC on testing set= 0.733148703338447\n",
      "n_estimators= 60 max_depth= 20  AUROC on testing set= 0.7342627657243042\n",
      "n_estimators= 60 max_depth= 22  AUROC on testing set= 0.7301346044269121\n",
      "n_estimators= 60 max_depth= 24  AUROC on testing set= 0.7280879100007305\n",
      "n_estimators= 60 max_depth= 26  AUROC on testing set= 0.7291918912995837\n",
      "n_estimators= 60 max_depth= 28  AUROC on testing set= 0.7269337716414639\n",
      "n_estimators= 70 max_depth= 2  AUROC on testing set= 0.6951456351815326\n",
      "n_estimators= 70 max_depth= 4  AUROC on testing set= 0.7066781211191466\n",
      "n_estimators= 70 max_depth= 6  AUROC on testing set= 0.7189795602308422\n",
      "n_estimators= 70 max_depth= 8  AUROC on testing set= 0.7258069398787348\n",
      "n_estimators= 70 max_depth= 10  AUROC on testing set= 0.729415706041347\n",
      "n_estimators= 70 max_depth= 12  AUROC on testing set= 0.7332947622178392\n",
      "n_estimators= 70 max_depth= 14  AUROC on testing set= 0.7342329753816934\n",
      "n_estimators= 70 max_depth= 16  AUROC on testing set= 0.7348544963109065\n",
      "n_estimators= 70 max_depth= 18  AUROC on testing set= 0.7345618964131785\n",
      "n_estimators= 70 max_depth= 20  AUROC on testing set= 0.7326402805172035\n",
      "n_estimators= 70 max_depth= 22  AUROC on testing set= 0.7322277156841259\n",
      "n_estimators= 70 max_depth= 24  AUROC on testing set= 0.7309525896705384\n",
      "n_estimators= 70 max_depth= 26  AUROC on testing set= 0.7271075900357952\n",
      "n_estimators= 70 max_depth= 28  AUROC on testing set= 0.728164380159252\n",
      "n_estimators= 80 max_depth= 2  AUROC on testing set= 0.6979804806779166\n",
      "n_estimators= 80 max_depth= 4  AUROC on testing set= 0.7089290963547374\n",
      "n_estimators= 80 max_depth= 6  AUROC on testing set= 0.717371539192052\n",
      "n_estimators= 80 max_depth= 8  AUROC on testing set= 0.7252890934326832\n",
      "n_estimators= 80 max_depth= 10  AUROC on testing set= 0.7318237563006794\n",
      "n_estimators= 80 max_depth= 12  AUROC on testing set= 0.734861143984221\n",
      "n_estimators= 80 max_depth= 14  AUROC on testing set= 0.7359806267806268\n",
      "n_estimators= 80 max_depth= 16  AUROC on testing set= 0.734917437358463\n",
      "n_estimators= 80 max_depth= 18  AUROC on testing set= 0.7362627218934912\n",
      "n_estimators= 80 max_depth= 20  AUROC on testing set= 0.7347635181532618\n",
      "n_estimators= 80 max_depth= 22  AUROC on testing set= 0.7319431076046461\n",
      "n_estimators= 80 max_depth= 24  AUROC on testing set= 0.7312496310906567\n",
      "n_estimators= 80 max_depth= 26  AUROC on testing set= 0.7295533347943605\n",
      "n_estimators= 80 max_depth= 28  AUROC on testing set= 0.729106742640076\n",
      "n_estimators= 90 max_depth= 2  AUROC on testing set= 0.6962144933888523\n",
      "n_estimators= 90 max_depth= 4  AUROC on testing set= 0.707757922419461\n",
      "n_estimators= 90 max_depth= 6  AUROC on testing set= 0.7195998977281028\n",
      "n_estimators= 90 max_depth= 8  AUROC on testing set= 0.7258174300533273\n",
      "n_estimators= 90 max_depth= 10  AUROC on testing set= 0.7298516326977866\n",
      "n_estimators= 90 max_depth= 12  AUROC on testing set= 0.7339320622397545\n",
      "n_estimators= 90 max_depth= 14  AUROC on testing set= 0.7341056030389363\n",
      "n_estimators= 90 max_depth= 16  AUROC on testing set= 0.7347698444006137\n",
      "n_estimators= 90 max_depth= 18  AUROC on testing set= 0.7348423405654175\n",
      "n_estimators= 90 max_depth= 20  AUROC on testing set= 0.7346917086711959\n",
      "n_estimators= 90 max_depth= 22  AUROC on testing set= 0.7330277302943969\n",
      "n_estimators= 90 max_depth= 24  AUROC on testing set= 0.7316948791000073\n",
      "n_estimators= 90 max_depth= 26  AUROC on testing set= 0.7299986996858793\n",
      "n_estimators= 90 max_depth= 28  AUROC on testing set= 0.7292476148732558\n",
      "n_estimators= 100 max_depth= 2  AUROC on testing set= 0.6965271824092336\n",
      "n_estimators= 100 max_depth= 4  AUROC on testing set= 0.7104480093505735\n",
      "n_estimators= 100 max_depth= 6  AUROC on testing set= 0.7191655928117466\n",
      "n_estimators= 100 max_depth= 8  AUROC on testing set= 0.725731653152166\n",
      "n_estimators= 100 max_depth= 10  AUROC on testing set= 0.730751479289941\n",
      "n_estimators= 100 max_depth= 12  AUROC on testing set= 0.7343618964131784\n",
      "n_estimators= 100 max_depth= 14  AUROC on testing set= 0.7365162685367812\n",
      "n_estimators= 100 max_depth= 16  AUROC on testing set= 0.7358241215574549\n",
      "n_estimators= 100 max_depth= 18  AUROC on testing set= 0.7344302140404705\n",
      "n_estimators= 100 max_depth= 20  AUROC on testing set= 0.7343052962232449\n",
      "n_estimators= 100 max_depth= 22  AUROC on testing set= 0.7329562860691067\n",
      "n_estimators= 100 max_depth= 24  AUROC on testing set= 0.733124625611805\n",
      "n_estimators= 100 max_depth= 26  AUROC on testing set= 0.732679757469501\n",
      "n_estimators= 100 max_depth= 28  AUROC on testing set= 0.7296980349185478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators=range(10,110,10)\n",
    "max_depth=range(2,30,2)\n",
    "\n",
    "def gridsearch_rf(n_estimators,max_depth):\n",
    "    params_scores = {}\n",
    "    for j in n_estimators:\n",
    "        for k in max_depth:\n",
    "            model = RandomForestClassifier(n_estimators=j,max_depth=k).fit(X_train,Y_train)\n",
    "            y_pred = model.predict_proba(X_test)[:,1]\n",
    "            score = roc_auc_score(Y_test, y_pred)\n",
    "            params_scores[(j,k)] = score\n",
    "            print(\"n_estimators=\",j,\"max_depth=\",k,\" AUROC on testing set=\",score)\n",
    "    return max(params_scores, key=params_scores.get)\n",
    "\n",
    "gridsearch_rf(n_estimators=n_estimators,max_depth=max_depth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
